{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "battery_power      int64\n",
       "blue               int64\n",
       "clock_speed      float64\n",
       "dual_sim           int64\n",
       "fc                 int64\n",
       "four_g             int64\n",
       "int_memory         int64\n",
       "m_dep            float64\n",
       "mobile_wt          int64\n",
       "n_cores            int64\n",
       "pc                 int64\n",
       "px_height          int64\n",
       "px_width           int64\n",
       "ram                int64\n",
       "sc_h               int64\n",
       "sc_w               int64\n",
       "talk_time          int64\n",
       "three_g            int64\n",
       "touch_screen       int64\n",
       "wifi               int64\n",
       "price_range        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "dataset = pd.read_csv('./datasets/train.csv')\n",
    "dataset=dataset.sample(frac=1)\n",
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features and labels\n",
    "X = dataset.iloc[:, 0:20].values\n",
    "y = dataset.iloc[:, 20].values\n",
    "\n",
    "\n",
    "\n",
    "# # Row normalization\n",
    "# for i, x in enumerate(X):\n",
    "#     minVal = np.min(x)\n",
    "#     norm_x = x - minVal\n",
    "#     maxVal = np.max(norm_x)\n",
    "#     norm_x /= maxVal\n",
    "#     X[i] = norm_x\n",
    "    \n",
    "# Column normalization\n",
    "for i in range(X.shape[1]):\n",
    "    x = X[:, i]\n",
    "    minVal = np.min(x)\n",
    "    norm_x = x - minVal\n",
    "    maxVal = np.max(norm_x)\n",
    "    norm_x /= maxVal\n",
    "    X[:, i] = norm_x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "X_l = list(X)\n",
    "\n",
    "cluster_data=[]\n",
    "for i in range(0,len(X_l)):\n",
    "    cluster_data.append(list(X_l[i]))\n",
    "    \n",
    "    \n",
    "inertias = []\n",
    "for i in range(1,20):\n",
    "    kmeans = KMeans(n_clusters=i)\n",
    "    kmeans.fit(cluster_data)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "plt.plot(range(1,20), inertias, marker='o')\n",
    "plt.title('Elbow plot')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of clusters chosen to be two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans=KMeans(n_clusters=2)\n",
    "kmeans.fit(cluster_data)\n",
    "\n",
    "kmeans_store=kmeans.labels_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters=[0,1]\n",
    "num_clusters=len(clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_partitions = [] # stores attributes of rows belonging to certain cluster in a dd list\n",
    "cluster_indices = [] # stores indices of rows belonging to certain cluster in a dd list\n",
    "\n",
    "for j in range(num_clusters):\n",
    "    partition = []\n",
    "    indices = []\n",
    "    for i in range(X_train.shape[0]):\n",
    "        if kmeans.labels_[i] == j:\n",
    "            partition.append(X_train[i])\n",
    "            indices.append(i)\n",
    "    cluster_partitions.append(partition)\n",
    "    cluster_indices.append(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_VALUES = [3,5,7,9,11,13,15]\n",
    "\n",
    "# Finding best k per cluster\n",
    "k_clusters = [0 for _ in range(num_clusters)]\n",
    "for i in range(num_clusters):\n",
    "    data = cluster_partitions[i]      # attribute rows belonging to cluster i\n",
    "    label = clusters[i]\n",
    "    most_count = [0 for _ in range(len(K_VALUES))]\n",
    "    \n",
    "    match = 0\n",
    "    for test_point_index, test_point in enumerate(data):\n",
    "        distances_dict = Counter()\n",
    "        cluster_count = Counter()\n",
    "\n",
    "        for index, train_point in enumerate(X_train):\n",
    "            distances_dict[index] = np.sum(np.square(test_point - train_point))\n",
    "\n",
    "        matched_k_list = []\n",
    "        index = 0\n",
    "        for K in K_VALUES:\n",
    "            for point_index, point in distances_dict.most_common()[-(K + 1):-1]:\n",
    "                cluster_count[y_train[point_index]] += 1\n",
    "\n",
    "            if cluster_count.most_common(1)[0][0] == y_train[test_point_index]:\n",
    "                matched_k_list.append(K)\n",
    "                most_count[index] += 1\n",
    "            index += 1\n",
    "\n",
    "        \n",
    "    # Taking the first best k value in case of ties\n",
    "    maxpos = most_count.index(max(most_count))\n",
    "    #print(most_count)\n",
    "\n",
    "    k_clusters[i] = K_VALUES[maxpos]               # ideal k value for the cluster\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "test_iter = list(X_test)\n",
    "\n",
    "final_acc = 0\n",
    "\n",
    "total = len(X_test)\n",
    "\n",
    "\n",
    "\n",
    "for j in clusters:\n",
    "    index = len(X_train)\n",
    "    num = 0\n",
    "    test_points_in_cluster=[]\n",
    "    test_y_in_cluster=[]\n",
    "    for i in test_iter:\n",
    "        if(kmeans_store[index] == j):     # check which test points belong to current cluster\n",
    "            test_points_in_cluster.append(i)\n",
    "            test_y_in_cluster.append(y[index])\n",
    "            num += 1\n",
    "        index += 1\n",
    "\n",
    "    classifier = KNeighborsClassifier(n_neighbors = 9, metric = 'minkowski', p = 2)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    test_points_in_cluster = np.array(test_points_in_cluster)\n",
    "    test_y_in_cluster = np.array(test_y_in_cluster)\n",
    "\n",
    "    \n",
    "    #y_pred = classifier.predict(test_points_in_cluster)\n",
    "    \n",
    "\n",
    "    \n",
    "    y_pred = classifier.predict(test_points_in_cluster)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    ac = accuracy_score(test_y_in_cluster, y_pred)\n",
    "    #print(ac)\n",
    "    final_acc += (num / total) * ac  # create a separate model for each cluster and take a frequency weighted average in the end\n",
    "    \n",
    "print(\"Final Accuracy is\", final_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
